
<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="shortcut icon" href="../assets/images/favicon.png">
      
      <meta name="generator" content="mkdocs-0.16.3, mkdocs-material-1.7.3">
    
    
      
        <title>Module 3 - Using Persistent Storage - Container-Native Storage Hands-on Lab - Storage SA Summit 2017</title>
      
    
    
      <script src="../assets/javascripts/modernizr-1df76c4e58.js"></script>
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application-acc56dad49.css">
      
    
    
      
        
        
        
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    
  </head>
  
  
  
  
    <body>
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <a href=".." title="Container-Native Storage Hands-on Lab - Storage SA Summit 2017" class="md-logo md-header-nav__button">
            <img src="../img/RedHat.svg" width="24" height="24">
          </a>
        
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <span class="md-flex__ellipsis md-header-nav__title">
          
            
              
                <span class="md-header-nav__parent">
                  Modules
                </span>
              
            
            Module 3 - Using Persistent Storage
          
        </span>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
          
<div class="md-search" data-md-component="search">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" required placeholder="Search" accesskey="s" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset">close</button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result" data-md-lang-search="">
          <div class="md-search-result__meta" data-md-lang-result-none="No matching documents" data-md-lang-result-one="1 matching document" data-md-lang-result-other="# matching documents">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    
      <i class="md-logo md-nav__button">
        <img src="../img/RedHat.svg">
      </i>
    
    Container-Native Storage Hands-on Lab - Storage SA Summit 2017
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Overview" class="md-nav__link">
      Overview
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2" checked>
    
    <label class="md-nav__link" for="nav-2">
      Modules
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Modules
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../module-1-ocp-in-5/" title="Module 1 - OpenShift in 5 Minutes" class="md-nav__link">
      Module 1 - OpenShift in 5 Minutes
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../module-2-deploy-cns/" title="Module 2 - Deploying Container-Native Storage" class="md-nav__link">
      Module 2 - Deploying Container-Native Storage
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        Module 3 - Using Persistent Storage
      </label>
    
    <a href="./" title="Module 3 - Using Persistent Storage" class="md-nav__link md-nav__link--active">
      Module 3 - Using Persistent Storage
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#creating-a-storageclass" title="Creating a StorageClass" class="md-nav__link">
    Creating a StorageClass
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#requesting-storage" title="Requesting Storage" class="md-nav__link">
    Requesting Storage
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-non-shared-storage-for-databases" title="Using non-shared storage for databases" class="md-nav__link">
    Using non-shared storage for databases
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#providing-shared-storage-to-multiple-application-instances" title="Providing shared storage to multiple application instances" class="md-nav__link">
    Providing shared storage to multiple application instances
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../module-4-cluster-ops/" title="Module 4 - Cluster Operations" class="md-nav__link">
      Module 4 - Cluster Operations
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../module-5-advanced/" title="Module 5 - Advanced Topics" class="md-nav__link">
      Module 5 - Advanced Topics
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#creating-a-storageclass" title="Creating a StorageClass" class="md-nav__link">
    Creating a StorageClass
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#requesting-storage" title="Requesting Storage" class="md-nav__link">
    Requesting Storage
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#using-non-shared-storage-for-databases" title="Using non-shared storage for databases" class="md-nav__link">
    Using non-shared storage for databases
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#providing-shared-storage-to-multiple-application-instances" title="Providing shared storage to multiple application instances" class="md-nav__link">
    Providing shared storage to multiple application instances
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>Module 3 - Using Persistent Storage</h1>
                
                <div class="admonition summary">
<p class="admonition-title">Overview</p>
<p>In this module you will use CNS as a developer would do in OpenShift. For that purpose you will dynamically provision storage both in standalone fashion and in context of an application deployment.</p>
</div>
<h2 id="creating-a-storageclass">Creating a StorageClass<a class="headerlink" href="#creating-a-storageclass" title="Permanent link">#</a></h2>
<p>OpenShift uses Kubernetes&rsquo; PersistentStorage facility to dynamically allocate storage of any kind for applications. This is a fairly simple framework in which only 3 components exists: the storage provider, the storage volume and the request for a storage volume.</p>
<p><a href="../img/cns_diagram_pvc.svg"><img alt="OpenShift Storage Lifecycle" src="../img/cns_diagram_pvc.svg" /></a></p>
<p>OpenShift knows non-ephemeral storage as &ldquo;persistent&rdquo; volumes. This is storage that is decoupled from pod lifecycles. Users can request such storage by submitting a <em>PersistentVolumeClaim</em> to the system, which carries aspects like desired capacity or access mode (shared, single, read-only).</p>
<p>A storage provider in the system is represented by a <em>StorageClass</em> and is referenced in the claim. Upon receiving the claim it talks to the API of the actual storage system to provision the storage.  </p>
<p>The storage is represented in OpenShift as a <em>PersistentVolume</em> which can directly be used by pods to mount it.</p>
<p>With these basics defined we can configure our system for CNS. First we will set up the credentials for CNS in OpenShift.</p>
<p>&#8680; Make sure you are logged on as <code>operator</code> and you are in the <code>default</code> namespace:</p>
<div class="codehilite"><pre><span></span>oc whoami
</pre></div>


<p>&#8680; If you are not <code>operator</code> log in again to the default namespace</p>
<div class="codehilite"><pre><span></span>oc login -u operator -n default
</pre></div>


<p>&#8680; Create an encoded value for the CNS admin user like below:</p>
<div class="codehilite"><pre><span></span>echo -n &quot;myS3cr3tpassw0rd&quot; | base64
</pre></div>


<p>The encoded string looks like this:</p>
<div class="codehilite"><pre><span></span>bXlTM2NyM3RwYXNzdzByZA==
</pre></div>


<p>We will store this encoded value in an OpenShift secret.</p>
<p>&#8680; Create a file called <code>cns-secret.yml</code> with the as per below (highlight shows where to put encoded password):</p>
<p><kbd>cns-secret.yml:</kbd></p>
<div class="codehilite"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">apiVersion</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="l l-Scalar l-Scalar-Plain">kind</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">Secret</span>
<span class="l l-Scalar l-Scalar-Plain">metadata</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">cns-secret</span>
  <span class="l l-Scalar l-Scalar-Plain">namespace</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">default</span>
<span class="l l-Scalar l-Scalar-Plain">data</span><span class="p p-Indicator">:</span>
<span class="hll">  <span class="l l-Scalar l-Scalar-Plain">key</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">bXlTM2NyM3RwYXNzdzByZA==</span>
</span><span class="l l-Scalar l-Scalar-Plain">type</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">kubernetes.io/glusterfs</span>
</pre></div>


<p>&#8680; Create the secret in OpenShift with the following command:</p>
<div class="codehilite"><pre><span></span>oc create -f cns-secret.yml
</pre></div>


<p>To represent CNS as a storage provider in the system you first have to create a StorageClass. Define by creating a file called <code>cns-storageclass.yml</code> which references the secret and the heketi URL shown earlier with the contents as below:</p>
<div class="admonition warning">
<p class="admonition-title">Important</p>
<p>Replace the <code>resturl</code> parameter with your heketi URL.</p>
</div>
<p><a name="storageclass-setup"></a></p>
<p><kbd>cns-storageclass.yml:</kbd></p>
<div class="codehilite"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">apiVersion</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">storage.k8s.io/v1beta1</span>
<span class="l l-Scalar l-Scalar-Plain">kind</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">StorageClass</span>
<span class="l l-Scalar l-Scalar-Plain">metadata</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">container-native-storage</span>
  <span class="l l-Scalar l-Scalar-Plain">annotations</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">storageclass.beta.kubernetes.io/is-default-class</span><span class="p p-Indicator">:</span> <span class="s">&quot;true&quot;</span>
<span class="l l-Scalar l-Scalar-Plain">provisioner</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">kubernetes.io/glusterfs</span>
<span class="l l-Scalar l-Scalar-Plain">parameters</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">resturl</span><span class="p p-Indicator">:</span> <span class="s">&quot;http://heketi-container-native-storage.cloudapps.34.252.58.209.nip.io&quot;</span>
  <span class="l l-Scalar l-Scalar-Plain">restauthenabled</span><span class="p p-Indicator">:</span> <span class="s">&quot;true&quot;</span>
  <span class="l l-Scalar l-Scalar-Plain">restuser</span><span class="p p-Indicator">:</span> <span class="s">&quot;admin&quot;</span>
  <span class="l l-Scalar l-Scalar-Plain">volumetype</span><span class="p p-Indicator">:</span> <span class="s">&quot;replicate:3&quot;</span>
  <span class="l l-Scalar l-Scalar-Plain">secretNamespace</span><span class="p p-Indicator">:</span> <span class="s">&quot;default&quot;</span>
  <span class="l l-Scalar l-Scalar-Plain">secretName</span><span class="p p-Indicator">:</span> <span class="s">&quot;cns-secret&quot;</span>
</pre></div>


<p>&#8680; Create the StorageClass in OpenShift with the following command:</p>
<div class="codehilite"><pre><span></span>oc create -f cns-storageclass.yml
</pre></div>


<p>With these components in place the system is ready to dynamically provision storage capacity from Container-native Storage.</p>
<hr />
<h2 id="requesting-storage">Requesting Storage<a class="headerlink" href="#requesting-storage" title="Permanent link">#</a></h2>
<p>To get storage provisioned as a user you have to &ldquo;claim&rdquo; storage. The <em>PersistentVolumeClaim</em> (PVC) basically acts a request to the system to provision storage with certain properties, like a specific capacity.<br />
Also the access mode is set here, where <em>ReadWriteOnce</em> allows one container at a time to mount this storage.</p>
<p>&#8680; Where are going to do this as a user. Login in as user <code>developer</code>:</p>
<div class="codehilite"><pre><span></span>oc login -u developer
</pre></div>


<p>&#8680; If you no projects, create one:</p>
<div class="codehilite"><pre><span></span>oc new-project playground
</pre></div>


<p>&#8680; Create a claim by specifying a file called <code>cns-pvc.yml</code> with the following contents:</p>
<p><kbd>cns-pvc.yml:</kbd></p>
<div class="codehilite"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">kind</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">PersistentVolumeClaim</span>
<span class="l l-Scalar l-Scalar-Plain">apiVersion</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="l l-Scalar l-Scalar-Plain">metadata</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">my-container-storage</span>
  <span class="l l-Scalar l-Scalar-Plain">annotations</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">volume.beta.kubernetes.io/storage-class</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">container-native-storage</span>
<span class="l l-Scalar l-Scalar-Plain">spec</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">accessModes</span><span class="p p-Indicator">:</span>
  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteOnce</span>
  <span class="l l-Scalar l-Scalar-Plain">resources</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">requests</span><span class="p p-Indicator">:</span>
      <span class="l l-Scalar l-Scalar-Plain">storage</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">10Gi</span>
</pre></div>


<p>With above PVC we are requesting 10 GiB of non-shared storage. Instead of <em>ReadWriteOnce</em> you could also have specified <em>ReadWriteOnly</em> (for read-only) and <em>ReadWriteMany</em> (for shared storage).</p>
<p>&#8680; Submit the PVC to the system like so:</p>
<div class="codehilite"><pre><span></span>oc create -f cns-pvc.yml
</pre></div>


<p>&#8680; After a couple of seconds, look at the requests state with the following command:</p>
<div class="codehilite"><pre><span></span>oc get pvc
</pre></div>


<p>You should see the PVC listed and in <em>Bound</em> state.</p>
<div class="codehilite"><pre><span></span>NAME                   STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
my-container-storage   Bound     pvc-382ac13d-4a9f-11e7-b56f-2cc2602a6dc8   10Gi       RWO           16s
</pre></div>


<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It may take a couple seconds for the claim to be in <strong>bound</strong>.</p>
</div>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>If the PVC is stuck in <em>PENDING</em> state you will need to investigate. Run <code>oc describe pvc/my-container-storage</code> to see a more detailed explanation. Typically there are two root causes - the StorageClass is not properly setup (wrong name, wrong credentials, incorrect secret name, wrong heketi URL, heketi service not up, heketi pod not up…) or the PVC is malformed (wrong StorageClass, name already taken …)</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>You can also do this step with the UI. Log on as <code>developer</code> and select or create a Project. Then go to the &ldquo;Storage&rdquo; tab. Select &ldquo;Create&rdquo; storage and make selections accordingly to the PVC described before.</p>
<p><a href="../img/openshift_pvc_create.png"><img alt="Creating a PersistentVolumeClaim" src="../img/openshift_pvc_create.png" /></a></p>
</div>
<p>When the claim was fulfilled successfully it is in the <em>Bound</em> state. That means the system has successfully (via the StorageClass) reached out to the storage backend (in our case GlusterFS). The backend in turn provisioned the storage and provided a handle back OpenShift. In OpenShift the provisioned storage is then represented by a <em>PersistentVolume</em> (PV) which is <em>bound</em> to the PVC.</p>
<p>&#8680; Look at the PVC for these details:</p>
<div class="codehilite"><pre><span></span>oc describe pvc/my-container-storage
</pre></div>


<p>The details of the PVC show against which <em>StorageClass</em> it has been submitted and the name of the <em>PersistentVolume</em> which was generated to fulfill the claim.</p>
<div class="codehilite"><pre><span></span><span class="hll">Name:           my-container-storage
</span>Namespace:      container-native-storage
StorageClass:   container-native-storage
Status:         Bound
<span class="hll">Volume:         pvc-382ac13d-4a9f-11e7-b56f-2cc2602a6dc8
</span>Labels:         &lt;none&gt;
Capacity:       10Gi
Access Modes:   RWO
No events.
</pre></div>


<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The PV name will be different in your environment since it’s automatically generated.</p>
</div>
<p>&#8680; Look at the corresponding PV by it’s name:</p>
<div class="codehilite"><pre><span></span>oc describe pv/pvc-382ac13d-4a9f-11e7-b56f-2cc2602a6dc8
</pre></div>


<p>The output shows several interesting things, like the access mode (RWO = ReadWriteOnce), the reclaim policy (what happens when the PV object gets deleted), the capacity and the type of storage backing this PV (in our case GlusterFS as part of CNS):</p>
<div class="codehilite"><pre><span></span>Name:           pvc-382ac13d-4a9f-11e7-b56f-2cc2602a6dc8
Labels:         &lt;none&gt;
StorageClass:   container-native-storage
<span class="hll">Status:         Bound
</span><span class="hll">Claim:          container-native-storage/my-container-storage
</span><span class="hll">Reclaim Policy: Delete
</span><span class="hll">Access Modes:   RWO
</span><span class="hll">Capacity:       10Gi
</span>Message:
Source:
<span class="hll">    Type:               Glusterfs (a Glusterfs mount on the host that shares a pod&#39;s lifetime)
</span>    EndpointsName:      glusterfs-dynamic-my-container-storage
    Path:               vol_304670f0d50bf5aa4717a69652bd48ff
    ReadOnly:           false
No events.
</pre></div>


<div class="admonition tip">
<p class="admonition-title">Why is it called <em>Bound</em>?</p>
<p>Originally PVs weren&rsquo;t automatically created. Hence in earlier documentation you may also find references about administrators actually <strong>pre-provisioning</strong> PVs. Later PVCs would &ldquo;pick up&rdquo; a suitable PV by looking at it’s capacity. When successful they are <em>bound</em> to this PV.<br />
This was needed for storage like NFS that does not have an API and therefore does not support <strong>dynamic provisioning</strong>. Hence it&rsquo;s called <strong>static provisioning</strong>.<br />
This kind of storage should not be used anymore as it requires manual intervention, risky capacity planning and incurs inefficient storage utilization.</p>
</div>
<p>Let’s release this storage capacity again.<br />
Storage is freed up by deleting the <strong>PVC</strong>. The PVC controls the lifecycle of the storage, not the PV.</p>
<div class="admonition caution">
<p class="admonition-title">Important</p>
<p>Never delete PVs that are dynamically provided. They are only handles for pods mounting the storage. Storage lifecycle is entirely controlled via PVCs.</p>
</div>
<p>&#8680; Delete the storage by deleting the PVC like this:</p>
<div class="codehilite"><pre><span></span>oc delete pvc/my-container-storage
</pre></div>


<hr />
<h2 id="using-non-shared-storage-for-databases">Using non-shared storage for databases<a class="headerlink" href="#using-non-shared-storage-for-databases" title="Permanent link">#</a></h2>
<p>Normally a user doesn’t request storage with a PVC directly. Rather the PVC is integrated in a larger template that describe the entire application. Such examples ship with OpenShift out of the box.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The steps described in this section can again also be done with the UI. For this purpose follow these steps similar to the one in Module 1:</p>
<blockquote>
<ol>
<li>
<p>Log on to the OpenShift UI as the <code>developer</code> user</p>
</li>
<li>
<p>If you don&rsquo;t have a project, create one called &lsquo;my-test-project&rsquo;, label and description is optional</p>
</li>
<li>
<p>In the Overview, next to the project’s name select <em>Add to project</em></p>
</li>
<li>
<p>In the <em>Browse Catalog</em> view select <em>Ruby</em> from the list of programming languages</p>
</li>
<li>
<p>Select the example app entitled <em>Rails + PostgreSQL (Persistent)</em></p>
</li>
<li>
<p>(optional) Change the <em>Volume Capacity</em> parameter to something greater than 1GiB, e.g. 15 GiB</p>
</li>
<li>
<p>Select <em>Create</em> to start deploying the app</p>
</li>
<li>
<p>Select <em>Continue to Overview</em> in the confirmation screen</p>
</li>
<li>
<p>Wait for the application deployment to finish and continue below at</p>
</li>
</ol>
</blockquote>
</div>
<hr />
<p>To create an application from the OpenShift Example templates on the CLI follow these steps.</p>
<p>&#8680; Create a new project with a name of your choice:</p>
<div class="codehilite"><pre><span></span>oc new-project my-test-project
</pre></div>


<p>To use the example applications that ship with OpenShift we can export and modify the template for a sample Ruby on Rails with PostgreSQL application. All these templates ship in pre-defined namespace called <code>openshift</code>.</p>
<p>&#8680; Export the template from the <code>openshift</code> namespace in YAML format:</p>
<div class="codehilite"><pre><span></span>oc export template/rails-pgsql-persistent -n openshift -o yaml &gt; rails-app-template.yml
</pre></div>


<p>In the file <code>rails-app-template.yml</code> you can now review the template for this entire application stack in all it’s glory.</p>
<div class="admonition hint">
<p class="admonition-title">What does the template file contain?</p>
<p>In essence it creates Ruby on Rails instance in a pod which functionality mimics a very basic blogging application. The blog articles are saved in a PostgreSQL database which runs in a separate pod.<br />
The template describes all OpenShift resources necessary to stand up the rails pod and the postgres pod and make them accessible via services and routes.<br />
In addition a PVC is issued (line 194) to supply this pod with persistent storage below the mount point <code>/var/lib/pgsql/data</code> (line 275).</p>
</div>
<p>The template contains a couple of parameters which default values we can override.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>To list all available parameters from this template run <code>oc process -f rails-app-template.yml --parameters</code><br />
The <code>oc process</code> command parses the template and replaces any parameters with their default values if not supplied explicitly like in the next step.</p>
</div>
<p>There is a parameter in the template is called <code>VOLUME_CAPACITY</code>. It is used to customize the capacity in the PVC. We will process the template with the CLI client and override this parameter with a value of <em>15Gi</em> as follows:</p>
<p>&#8680; Render the template with the custom parameter value as follows:</p>
<div class="codehilite"><pre><span></span>oc process -f rails-app-template.yml -o yaml -p VOLUME_CAPACITY=15Gi &gt; my-rails-app.yml
</pre></div>


<p>The result <code>my-rails-app.yml</code> file contains all resources including our custom PVC for this application.</p>
<p>&#8680; Deploy these resources like so:</p>
<div class="codehilite"><pre><span></span>oc create -f my-rails-app.yml
</pre></div>


<p>Among various OpenShift resource also our PVC will be created:</p>
<div class="codehilite"><pre><span></span>secret &quot;rails-pgsql-persistent&quot; created
service &quot;rails-pgsql-persistent&quot; created
route &quot;rails-pgsql-persistent&quot; created
imagestream &quot;rails-pgsql-persistent&quot; created
buildconfig &quot;rails-pgsql-persistent&quot; created
deploymentconfig &quot;rails-pgsql-persistent&quot; created
<span class="hll">persistentvolumeclaim &quot;postgresql&quot; created
</span>service &quot;postgresql&quot; created
deploymentconfig &quot;postgresql&quot; created
</pre></div>


<p>You can now use the OpenShift UI (while being logged in the newly created project) to follow the deployment process.</p>
<p>&#8680; Alternatively watch the containers deploy like this:</p>
<div class="codehilite"><pre><span></span>oc get pods -w
</pre></div>


<p>The complete output should look like this:</p>
<div class="codehilite"><pre><span></span>NAME                             READY     STATUS              RESTARTS   AGE
postgresql-1-deploy              0/1       ContainerCreating   0          11s
rails-pgsql-persistent-1-build   0/1       ContainerCreating   0          11s
NAME                  READY     STATUS    RESTARTS   AGE
postgresql-1-deploy   1/1       Running   0          14s
postgresql-1-81gnm   0/1       Pending   0         0s
postgresql-1-81gnm   0/1       Pending   0         0s
rails-pgsql-persistent-1-build   1/1       Running   0         19s
postgresql-1-81gnm   0/1       Pending   0         15s
postgresql-1-81gnm   0/1       ContainerCreating   0         16s
postgresql-1-81gnm   0/1       Running   0         47s
postgresql-1-81gnm   1/1       Running   0         4m
postgresql-1-deploy   0/1       Completed   0         4m
postgresql-1-deploy   0/1       Terminating   0         4m
postgresql-1-deploy   0/1       Terminating   0         4m
rails-pgsql-persistent-1-deploy   0/1       Pending   0         0s
rails-pgsql-persistent-1-deploy   0/1       Pending   0         0s
rails-pgsql-persistent-1-deploy   0/1       ContainerCreating   0         0s
rails-pgsql-persistent-1-build   0/1       Completed   0         11m
rails-pgsql-persistent-1-deploy   1/1       Running   0         6s
rails-pgsql-persistent-1-hook-pre   0/1       Pending   0         0s
rails-pgsql-persistent-1-hook-pre   0/1       Pending   0         0s
rails-pgsql-persistent-1-hook-pre   0/1       ContainerCreating   0         0s
rails-pgsql-persistent-1-hook-pre   1/1       Running   0         6s
rails-pgsql-persistent-1-hook-pre   0/1       Completed   0         15s
rails-pgsql-persistent-1-dkj7w   0/1       Pending   0         0s
rails-pgsql-persistent-1-dkj7w   0/1       Pending   0         0s
rails-pgsql-persistent-1-dkj7w   0/1       ContainerCreating   0         0s
rails-pgsql-persistent-1-dkj7w   0/1       Running   0         1m
rails-pgsql-persistent-1-dkj7w   1/1       Running   0         1m
rails-pgsql-persistent-1-deploy   0/1       Completed   0         1m
rails-pgsql-persistent-1-deploy   0/1       Terminating   0         1m
rails-pgsql-persistent-1-deploy   0/1       Terminating   0         1m
rails-pgsql-persistent-1-hook-pre   0/1       Terminating   0         1m
rails-pgsql-persistent-1-hook-pre   0/1       Terminating   0         1m
</pre></div>


<p>Exit out of the watch mode with: <kbd>Ctrl</kbd> + <kbd>c</kbd></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It may take up to 5 minutes for the deployment to complete.</p>
<p>If you did it via the UI the deployment is finished when both, rails app and postgres database are up and running:</p>
<p><a href="../img/openshift_rails_deploy.png"><img alt="OpenShift Rails Example Deployment" src="../img/openshift_rails_deploy.png" /></a></p>
</div>
<p>You should also see a PVC being issued and in the <em>Bound</em> state.</p>
<p>&#8680; Look at the PVC created:</p>
<div class="codehilite"><pre><span></span>oc get pvc/postgresql
</pre></div>


<p>Output:</p>
<div class="codehilite"><pre><span></span>NAME         STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
postgresql   Bound     pvc-6c348fbb-4e9d-11e7-970e-0a9938370404   15Gi       RWO           4m
</pre></div>


<div class="admonition tip">
<p class="admonition-title">Why did this even work?</p>
<p>If you paid close attention you likely noticed that the PVC in the template does not specify a particular <em>StorageClass</em>. This still yields a PV deployed because our <em>StorageClass</em> has actually been defined as the system-wide default. PVCs that don&rsquo;t specify a <em>StorageClass</em> will use the default class.</p>
</div>
<p>Now go ahead and try out the application. The overview page in the OpenShift UI will tell you the <code>route</code> which has been deployed as well. Use it and append <code>/articles</code> to the URL to get to the actual app.</p>
<p>&#8680; Otherwise get it on the CLI like this:</p>
<div class="codehilite"><pre><span></span>oc get route
</pre></div>


<p>Output:</p>
<div class="codehilite"><pre><span></span>NAME                     HOST/PORT                                                               PATH      SERVICES                 PORT      TERMINATION   WILDCARD
rails-pgsql-persistent   rails-pgsql-persistent-my-test-project.cloudapps.34.252.58.209.nip.io             rails-pgsql-persistent   &lt;all&gt;                   None
</pre></div>


<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Again, the URL will be slightly different for you.</p>
</div>
<p>Following this output, point your browser to the URL and append <strong>/articles</strong> to reach the actual application, in this case:</p>
<p>http://<em>rails-pgsql-persistent-my-test-project.cloudapps.34.252.58.209.nip.io</em>/<strong>articles</strong></p>
<p>You should be able to successfully create articles and comments. The username/password to create articles and comments is by default <strong>openshift</strong>/<strong>secret</strong>.<br />
When they are saved they are actually saved in the PostgreSQL database which stores it’s table spaces on a GlusterFS volume provided by CNS.</p>
<p>Now let’s take a look at how this was actually achieved.</p>
<p>&#8680; A normal user cannot see the details of a PersistentVolume. Log in as <code>operator</code>:</p>
<div class="codehilite"><pre><span></span>oc login -u operator
</pre></div>


<p>&#8680; Look at the PVC to determine the PV:</p>
<div class="codehilite"><pre><span></span>oc get pvc
</pre></div>


<p>Output:</p>
<div class="codehilite"><pre><span></span>NAME         STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
postgresql   Bound     pvc-6c348fbb-4e9d-11e7-970e-0a9938370404   15Gi       RWO           10m
</pre></div>


<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Your volume (PV) name will be different as it’s dynamically generated.</p>
</div>
<p>&#8680; Look at the details of this PV:</p>
<div class="codehilite"><pre><span></span>oc describe pv/pvc-6c348fbb-4e9d-11e7-970e-0a9938370404
</pre></div>


<p>Output shows (in highlight) the name of the volume, the backend type (GlusterFS) and the volume name GlusterFS uses internally.</p>
<div class="codehilite"><pre><span></span><span class="hll">Name:       pvc-6c348fbb-4e9d-11e7-970e-0a9938370404
</span>Labels:     &lt;none&gt;
StorageClass:   container-native-storage
Status:     Bound
Claim:      my-test-project/postgresql
Reclaim Policy: Delete
Access Modes:   RWO
Capacity:   15Gi
Message:
Source:
<span class="hll">    Type:       Glusterfs (a Glusterfs mount on the host that shares a pod&#39;s lifetime)
</span>    EndpointsName:  glusterfs-dynamic-postgresql
<span class="hll">    Path:       vol_efac3ddb9d339fa680c0807a1d91c5a3
</span>    ReadOnly:       false
No events.
</pre></div>


<p>Note the GlusterFS volume name, in this case <code>vol_e8fe7f46fedf7af7628feda0dcbf2f60</code>.</p>
<p>&#8680; Now let’s switch to the namespace we used for CNS deployment:</p>
<div class="codehilite"><pre><span></span>oc project container-native-storage
</pre></div>


<p>&#8680; Look at the GlusterFS pods running</p>
<div class="codehilite"><pre><span></span>oc get pods -o wide
</pre></div>


<p>Pick one of the GlusterFS pods by name (which one is not important):</p>
<div class="codehilite"><pre><span></span>NAME              READY     STATUS    RESTARTS   AGE       IP           NODE
glusterfs-5rc2g   1/1       Running   0          51m       10.0.2.101   node-1.lab
glusterfs-jbvdk   1/1       Running   0          51m       10.0.3.102   node-2.lab
glusterfs-rchtr   1/1       Running   0          51m       10.0.4.103   node-3.lab
heketi-1-tn0s9    1/1       Running   0          49m       10.130.2.3   node-6.lab
</pre></div>


<p><strong>Remember the IP address</strong> of the pod you select. In this case <code>10.0.2.101</code>.</p>
<p>&#8680; Log on to GlusterFS pod with a remote terminal session like so:</p>
<div class="codehilite"><pre><span></span>oc rsh glusterfs-5rc2g
</pre></div>


<p>You will end up in shell session in the container with root privileges.</p>
<div class="codehilite"><pre><span></span>sh-4.2#
</pre></div>


<p>You have now access to this container’s process and filesystem namespace which has the GlusterFS CLI utilities installed.</p>
<p>&#8680; Let’s list all known volumes:</p>
<div class="codehilite"><pre><span></span>sh-4.2# gluster volume list
</pre></div>


<p>You will see two volumes:</p>
<div class="codehilite"><pre><span></span>heketidbstorage
vol_efac3ddb9d339fa680c0807a1d91c5a3
</pre></div>


<ul>
<li>
<p><code>heketidbstorage</code> is a internal-only volume dedicated to heketi’s internal database.</p>
</li>
<li>
<p><code>vol_efac3ddb9d339fa680c0807a1d91c5a3</code> is the volume backing the PV of the PostgreSQL database deployed earlier.</p>
</li>
</ul>
<p>&#8680; Interrogate GlusterFS about the topology of this volume:</p>
<div class="codehilite"><pre><span></span>sh-4.2# gluster volume info vol_efac3ddb9d339fa680c0807a1d91c5a3
</pre></div>


<p>The output will show you how the volume has been created. You will also see that the pod you are currently logged on serves one the bricks (in highlight).</p>
<div class="codehilite"><pre><span></span>Volume Name: vol_efac3ddb9d339fa680c0807a1d91c5a3
Type: Replicate
Volume ID: cfaccdec-3c97-4e43-b80f-c9677e7a726a
Status: Started
Snapshot Count: 0
Number of Bricks: 1 x 3 = 3
Transport-type: tcp
Bricks:
Brick1: 10.0.3.102:/var/lib/heketi/mounts/vg_8ea71174529a35f41fc0d1b288da6299/brick_b2e6975e246d896038604a7c0efcd83f/brick
<span class="hll">Brick2: 10.0.2.101:/var/lib/heketi/mounts/vg_2a49883a5cb39c3b845477ff85a729ba/brick_c5b00eeae2c57862b4eddeeb9b3903ad/brick
</span>Brick3: 10.0.4.103:/var/lib/heketi/mounts/vg_41b8a921f8e6d31cb04c7dd35b6b4cf2/brick_4f691eb2ba90a3ee31cb882f12786400/brick
Options Reconfigured:
transport.address-family: inet
performance.readdir-ahead: on
nfs.disable: on
</pre></div>


<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Identify the right brick by looking at the host IP of the pod you have just logged on to. <code>oc get pods -o wide</code> will give you this information.</p>
</div>
<p>GlusterFS created this volume as a 3-way replica set across all GlusterFS pods, therefore across all your OpenShift App nodes running CNS. This is currently the only supported volume type in production. Later you will see how can schedule (unsupported) volume types like dispersed or distributed.</p>
<p>&#8680; You can even look at the local brick:</p>
<div class="codehilite"><pre><span></span>sh-4.2# ls -ahl /var/lib/heketi/mounts/vg_2a49883a5cb39c3b845477ff85a729ba/brick_c5b00eeae2c57862b4eddeeb9b3903ad/brick
total 16K
drwxrwsr-x.   5 root       2001   57 Jun  6 14:44 .
drwxr-xr-x.   3 root       root   19 Jun  6 14:44 ..
drw---S---. 263 root       2001 8.0K Jun  6 14:46 .glusterfs
drwxr-sr-x.   3 root       2001   25 Jun  6 14:44 .trashcan
drwx------.  20 1000080000 2001 8.0K Jun  6 14:46 userdata

sh-4.2# ls -ahl /var/lib/heketi/mounts/vg_2a49883a5cb39c3b845477ff85a729ba/brick_c5b00eeae2c57862b4eddeeb9b3903ad/brick/userdata

total 68K
drwx------. 20 1000080000 2001 8.0K Jun  6 14:46 .
drwxrwsr-x.  5 root       2001   57 Jun  6 14:44 ..
-rw-------.  2 1000080000 root    4 Jun  6 14:44 PG_VERSION
drwx------.  6 1000080000 root   54 Jun  6 14:46 base
drwx------.  2 1000080000 root 8.0K Jun  6 14:47 global
drwx------.  2 1000080000 root   18 Jun  6 14:44 pg_clog
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_commit_ts
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_dynshmem
-rw-------.  2 1000080000 root 4.6K Jun  6 14:46 pg_hba.conf
-rw-------.  2 1000080000 root 1.6K Jun  6 14:44 pg_ident.conf
drwx------.  2 1000080000 root   32 Jun  6 14:46 pg_log
drwx------.  4 1000080000 root   39 Jun  6 14:44 pg_logical
drwx------.  4 1000080000 root   36 Jun  6 14:44 pg_multixact
drwx------.  2 1000080000 root   18 Jun  6 14:46 pg_notify
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_replslot
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_serial
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_snapshots
drwx------.  2 1000080000 root    6 Jun  6 14:46 pg_stat
drwx------.  2 1000080000 root   84 Jun  6 15:16 pg_stat_tmp
drwx------.  2 1000080000 root   18 Jun  6 14:44 pg_subtrans
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_tblspc
drwx------.  2 1000080000 root    6 Jun  6 14:44 pg_twophase
drwx------.  3 1000080000 root   60 Jun  6 14:44 pg_xlog
-rw-------.  2 1000080000 root   88 Jun  6 14:44 postgresql.auto.conf
-rw-------.  2 1000080000 root  21K Jun  6 14:46 postgresql.conf
-rw-------.  2 1000080000 root   46 Jun  6 14:46 postmaster.opts
-rw-------.  2 1000080000 root   89 Jun  6 14:46 postmaster.pid
</pre></div>


<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The exact path name will be different in your environment as it has been automatically generated.</p>
</div>
<p>You are looking at the PostgreSQL internal data file structure from the perspective of the GlusterFS server side. Evidence that the database uses CNS.</p>
<p>Clients, like the OpenShift nodes and their application pods talk to this storage with the GlusterFS protocol as it where an ordinary GlusterFS deployment.<br />
When a pod starts that mounts storage from a PV backed by CNS the GlusterFS mount plugin in OpenShift will mount the GlusterFS volume on the right App Node and then <em>bind-mount</em> this directory to the right pod.<br />
This is happen transparently to the application and looks like a normal local filesystem inside the pod.</p>
<p>&#8680; You may exit your remote session to the GlusterFS pod.</p>
<div class="codehilite"><pre><span></span>sh-4.2# exit
</pre></div>


<hr />
<h2 id="providing-shared-storage-to-multiple-application-instances">Providing shared storage to multiple application instances<a class="headerlink" href="#providing-shared-storage-to-multiple-application-instances" title="Permanent link">#</a></h2>
<p>In the previous example we provisioned an RWO PV - the volume is only usable with one pod at a time. RWO is what most of the OpenShift storage backends support.<br />
So far only very few options, like the basic NFS support existed, to provide a PersistentVolume to more than one container at once. The access mode used for this is <strong>ReadWriteMany</strong>.</p>
<p>With CNS this capabilities is now available to all OpenShift deployments, no matter where they are deployed. To demonstrate this capability with an application we will deploy a PHP-based file uploader that has multiple front-end instances sharing a common storage repository.</p>
<p>&#8680; Log back in as developer</p>
<div class="codehilite"><pre><span></span>oc login -u developer
</pre></div>


<p>&#8680; First make sure you are still in the example project created earlier</p>
<div class="codehilite"><pre><span></span>oc project my-test-project
</pre></div>


<p>&#8680; Next deploy the example application:</p>
<div class="codehilite"><pre><span></span>oc new-app openshift/php:7.0~https://github.com/christianh814/openshift-php-upload-demo --name=file-uploader
</pre></div>


<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is yet another way to build and launch an application from source code in OpenShift. The content before the ~ is the name of a Source-to-Image builder (a container that knows how to build applications of a certain type from source, in this case PHP) and the URL following is a GitHub repository hosting the source code.<br />
Feel free to check it out.</p>
</div>
<p>Output:</p>
<div class="codehilite"><pre><span></span>--&gt; Found image a1ebebb (6 weeks old) in image stream &quot;openshift/php&quot; under tag &quot;7.0&quot; for &quot;openshift/php:7.0&quot;

    Apache 2.4 with PHP 7.0
    -----------------------
    Platform for building and running PHP 7.0 applications

    Tags: builder, php, php70, rh-php70

    * A source build using source code from https://github.com/christianh814/openshift-php-upload-demo will be created
      * The resulting image will be pushed to image stream &quot;file-uploader:latest&quot;
      * Use &#39;start-build&#39; to trigger a new build
    * This image will be deployed in deployment config &quot;file-uploader&quot;
    * Port 8080/tcp will be load balanced by service &quot;file-uploader&quot;
      * Other containers can access this service through the hostname &quot;file-uploader&quot;

--&gt; Creating resources ...
    imagestream &quot;file-uploader&quot; created
    buildconfig &quot;file-uploader&quot; created
    deploymentconfig &quot;file-uploader&quot; created
    service &quot;file-uploader&quot; created
--&gt; Success
    Build scheduled, use &#39;oc logs -f bc/file-uploader&#39; to track its progress.
    Run &#39;oc status&#39; to view your app.
</pre></div>


<p>&#8680; Wait for the application to be deployed with the suggest command:</p>
<div class="codehilite"><pre><span></span>oc logs -f bc/file-uploader
</pre></div>


<p>The follow-mode of the above command ends automatically when the build is successful and you return to your shell.</p>
<div class="codehilite"><pre><span></span>...
Cloning &quot;https://github.com/christianh814/openshift-php-upload-demo&quot; ...
        Commit: 7508da63d78b4abc8d03eac480ae930beec5d29d (Update index.html)
        Author: Christian Hernandez &lt;christianh814@users.noreply.github.com&gt;
        Date:   Thu Mar 23 09:59:38 2017 -0700
---&gt; Installing application source...
Pushing image 172.30.120.134:5000/my-test-project/file-uploader:latest ...
Pushed 0/5 layers, 2% complete
Pushed 1/5 layers, 20% complete
Pushed 2/5 layers, 40% complete
Push successful
</pre></div>


<p>&#8680; When the build is completed ensure the pods are running:</p>
<div class="codehilite"><pre><span></span>oc get pods
</pre></div>


<p>Among your existing pods you should see new pods running.</p>
<div class="codehilite"><pre><span></span>NAME                             READY     STATUS      RESTARTS   AGE
file-uploader-1-build            0/1       Completed   0          2m
file-uploader-1-k2v0d            1/1       Running     0          1m
...
</pre></div>


<p>A service has been created for our app but not exposed yet.</p>
<p>&#8680; Let’s fix this:</p>
<div class="codehilite"><pre><span></span>oc expose svc/file-uploader
</pre></div>


<p>&#8680; Check the route that has been created:</p>
<div class="codehilite"><pre><span></span>oc get route/file-uploader
</pre></div>


<p>The route forwards all traffic to port 8080 of the container running the app.</p>
<div class="codehilite"><pre><span></span>NAME            HOST/PORT                                                      PATH      SERVICES        PORT       TERMINATION   WILDCARD
file-uploader   file-uploader-my-test-project.cloudapps.34.252.58.209.nip.io             file-uploader   8080-tcp                 None
</pre></div>


<p>Point your browser the the URL advertised by the route (in this case http://file-uploader-my-test-project.cloudapps.34.252.58.209.nip.io)</p>
<p>The application simply lists all file previously uploaded and offers the ability to upload new ones as well as download the existing data. Right now there is nothing.</p>
<p>Select an arbitrary from your local system and upload it to the app.</p>
<p><a href="../img/uploader_screen_upload.png"><img alt="A simple PHP-based file upload tool" src="../img/uploader_screen_upload.png" /></a></p>
<p>After uploading a file validate it has been stored locally in the container by following the link <em>List Uploaded Files</em> in the browser.</p>
<p>Let&rsquo;s see how this is stored locally in the container.</p>
<p>&#8680; List the running pods of our application:</p>
<div class="codehilite"><pre><span></span>oc get pods | grep file-uploader
</pre></div>


<p>You will see two entries:</p>
<div class="codehilite"><pre><span></span>file-uploader-1-build            0/1       Completed   0          7m
file-uploader-1-k2v0d            1/1       Running     0          6m
</pre></div>


<p>Note the name of the single pod currently running the app: <strong>file-uploader-1-k2v0d</strong>.<br />
The container called <code>file-uploader-1-build</code> is the builder container that deployed the application and it has already terminated.</p>
<p>&#8680; Log into the application pod via a remote session (using the name noted earlier):</p>
<div class="codehilite"><pre><span></span>oc rsh file-uploader-1-k2v0d
</pre></div>


<p>In the container explore the directory in which the uploaded files will be stored.</p>
<div class="codehilite"><pre><span></span>sh-4.2$ cd uploaded
sh-4.2$ pwd
/opt/app-root/src/uploaded
sh-4.2$ ls -lh
total 16K
-rw-r--r--. 1 1000080000 root 16K May 26 09:32 cns-deploy-4.0.0-15.el7rhgs.x86_64.rpm.gz
</pre></div>


<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The exact name of the pod will be different in your environment.</p>
</div>
<p>The app should also list the file in the overview:</p>
<p><a href="../img/uploader_screen_list.png"><img alt="The file has been uploaded and can be downloaded again" src="../img/uploader_screen_list.png" /></a></p>
<p>This pod currently does not use any persistent storage. It stores the file locally.</p>
<div class="admonition danger">
<p class="admonition-title">Important</p>
<p>Never store data in a pod. It’s ephemeral by definition and will be lost as soon as the pod terminates.</p>
</div>
<p>Let’s see when this become a problem.</p>
<p>&#8680; Exit out of the container shell:</p>
<div class="codehilite"><pre><span></span>sh-4.2$ exit
</pre></div>


<p>&#8680; Let’s scale the deployment to 3 instances of the app:</p>
<div class="codehilite"><pre><span></span>oc scale dc/file-uploader --replicas=3
</pre></div>


<p>&#8680; Watch the additional pods getting spawned:</p>
<div class="codehilite"><pre><span></span>oc get pods
</pre></div>


<p>You will see 2 additional pods being spawned:</p>
<div class="codehilite"><pre><span></span>NAME                             READY     STATUS      RESTARTS   AGE
file-uploader-1-3cgh1            1/1       Running     0          20s
file-uploader-1-3hckj            1/1       Running     0          20s
file-uploader-1-build            0/1       Completed   0          4m
file-uploader-1-k2v0d            1/1       Running     0          3m
...
</pre></div>


<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The pod names will be different in your environment since they are automatically generated.</p>
</div>
<p>These 3 pods now make up our application. OpenShift will load balance incoming traffic between them.<br />
However, when you log on to one of the new instances you will see they have no data.</p>
<p>&#8680; Log on to one of the new containers:</p>
<div class="codehilite"><pre><span></span>oc rsh file-uploader-1-3cgh1
</pre></div>


<p>&#8680; Again check the upload directory:</p>
<div class="codehilite"><pre><span></span>sh-4.2$ cd uploaded
sh-4.2$ pwd
/opt/app-root/src/uploaded
sh-4.2$ ls -hl
total 0
</pre></div>


<p>It&rsquo;s empty because the previously uploaded files were stored locally in the first container and are not available to the others.<br />
Similarly, other users of the app will sometimes see your uploaded files and sometimes not. With the deployment scaled to 3 instances OpenShifts router will simply round-robin across them. Whenever the load balancing service in OpenShift points to the pod that has the file stored locally users will see it or not. You can simulate this with another instance of your browser in &ldquo;Incognito mode&rdquo; pointing to your app.</p>
<p>The app is of course not usable like this. We can fix this by providing shared storage to this app.</p>
<p>&#8680; First create a PVC with the appropriate setting in a file called <code>cns-rwx-pvc.yml</code> with below contents:</p>
<p><kbd>cns-rwx-pvc.yml:</kbd></p>
<div class="codehilite"><pre><span></span><span class="l l-Scalar l-Scalar-Plain">kind</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">PersistentVolumeClaim</span>
<span class="l l-Scalar l-Scalar-Plain">apiVersion</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="l l-Scalar l-Scalar-Plain">metadata</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">my-shared-storage</span>
  <span class="l l-Scalar l-Scalar-Plain">annotations</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">volume.beta.kubernetes.io/storage-class</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">container-native-storage</span>
<span class="l l-Scalar l-Scalar-Plain">spec</span><span class="p p-Indicator">:</span>
  <span class="l l-Scalar l-Scalar-Plain">accessModes</span><span class="p p-Indicator">:</span>
<span class="hll">  <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteMany</span>
</span>  <span class="l l-Scalar l-Scalar-Plain">resources</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">requests</span><span class="p p-Indicator">:</span>
      <span class="l l-Scalar l-Scalar-Plain">storage</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">10Gi</span>
</pre></div>


<p>Notice the access mode explicitly requested to be <code>ReadWriteMany</code> (also referred to as RWX). Storage provisioned like this can be mounted by multiple containers on multiple hosts at the same time.</p>
<p>&#8680; Submit the request to the system:</p>
<div class="codehilite"><pre><span></span>oc create -f cns-rwx-pvc.yml
</pre></div>


<p>&#8680; Let’s look at the result:</p>
<div class="codehilite"><pre><span></span>oc get pvc
</pre></div>


<p><code>ACCESSMODES</code> is set to <code>RWX</code>:</p>
<div class="codehilite"><pre><span></span>NAME                STATUS    VOLUME                                     CAPACITY   ACCESSMODES   AGE
my-shared-storage   Bound     pvc-62aa4dfe-4ad2-11e7-b56f-2cc2602a6dc8   10Gi       RWX           22s
...
</pre></div>


<p>We can now update the <em>DeploymentConfig</em> of our application to use this PVC to provide the application with persistent, shared storage for uploads.</p>
<p>&#8680; Update the configuration of the application by adding a volume claim like this:</p>
<div class="codehilite"><pre><span></span>oc volume dc/file-uploader --add --name=shared-storage --type=persistentVolumeClaim --claim-name=my-shared-storage --mount-path=/opt/app-root/src/uploaded
</pre></div>


<p>Our app will now re-deploy (in a rolling fashion) with the new settings - all pods will mount the volume identified by the PVC under /opt/app-root/src/upload (the path is predictable so we can hard-code it here).</p>
<p>&#8680; You can watch it like this:</p>
<div class="codehilite"><pre><span></span>oc logs dc/file-uploader -f
</pre></div>


<p>The new <code>DeploymentConfig</code> will supersede the old one.</p>
<div class="codehilite"><pre><span></span>--&gt; Scaling up file-uploader-2 from 0 to 3, scaling down file-uploader-1 from 3 to 0 (keep 3 pods available, don&#39;t exceed 4 pods)
    Scaling file-uploader-2 up to 1
    Scaling file-uploader-1 down to 2
    Scaling file-uploader-2 up to 2
    Scaling file-uploader-1 down to 1
    Scaling file-uploader-2 up to 3
    Scaling file-uploader-1 down to 0
--&gt; Success
</pre></div>


<p>The new config <code>file-uploader-2</code> will have 3 pods all sharing the same storage.</p>
<p>&#8680; Get the names of the new pods:</p>
<div class="codehilite"><pre><span></span>oc get pods
</pre></div>


<p>Output:</p>
<div class="codehilite"><pre><span></span>NAME                             READY     STATUS      RESTARTS   AGE
file-uploader-1-build            0/1       Completed   0          18m
file-uploader-2-jd22b            1/1       Running     0          1m
file-uploader-2-kw9lq            1/1       Running     0          2m
file-uploader-2-xbz24            1/1       Running     0          1m
...
</pre></div>


<p>Try it out in your application: upload new files and watch them being visible from within all application pods. In new browser sessions, simulating other users, the application behaves normally as it circles through the pods between browser requests.</p>
<div class="codehilite"><pre><span></span>[root@master ~]# oc rsh file-uploader-2-jd22b
sh-4.2$ ls -lh uploaded
total 16K
-rw-r--r--. 1 1000080000 root 16K May 26 10:21 cns-deploy-4.0.0-15.el7rhgs.x86_64.rpm.gz
sh-4.2$ exit
exit
[root@master ~]# oc rsh file-uploader-2-kw9lq
sh-4.2$ ls -lh uploaded
-rw-r--r--. 1 1000080000 root 16K May 26 10:21 cns-deploy-4.0.0-15.el7rhgs.x86_64.rpm.gz
sh-4.2$ exit
exit
[root@master ~]# oc rsh file-uploader-2-xbz24
sh-4.2$ ls -lh uploaded
-rw-r--r--. 1 1000080000 root 16K May 26 10:21 cns-deploy-4.0.0-15.el7rhgs.x86_64.rpm.gz
sh-4.2$ exit
</pre></div>


<p>That’s it. You have successfully provided shared storage to pods throughout the entire system, therefore avoiding the need for data to be replicated at the application level to each pod.</p>
<p>With CNS this is available wherever OpenShift is deployed with no external dependency.</p>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../module-2-deploy-cns/" title="Module 2 - Deploying Container-Native Storage" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Module 2 - Deploying Container-Native Storage
              </span>
            </div>
          </a>
        
        
          <a href="../module-4-cluster-ops/" title="Module 4 - Cluster Operations" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Module 4 - Cluster Operations
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="http://www.mkdocs.org" title="MkDocs">MkDocs</a>
        and
        <a href="http://squidfunk.github.io/mkdocs-material/" title="Material for MkDocs">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application-b30566c560.js"></script>
      
      
      <script>app.initialize({url:{base:".."}})</script>
      
    
    
      
    
  </body>
</html>